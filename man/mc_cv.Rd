% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cv.R
\name{mc_cv}
\alias{mc_cv}
\title{New function to compute optimal value of regularization parameter based on K-fold cross-validation}
\usage{
mc_cv(
  fit,
  Kfold = 5,
  nweight = NULL,
  weighting = TRUE,
  wtype = "size",
  type = "MSFE",
  l1length = 100,
  normalize = TRUE
)
}
\arguments{
\item{fit}{fitted object returned from mc_reg()}

\item{Kfold}{K-fold cross-validation}

\item{nweight}{vector of length K indicating weights for MSFE measure}

\item{type}{MSFE or MAFE}

\item{l1length}{length sparsity grid l1 penalty}

\item{asym}{flag: asymmetric forecast error measure or not}
}
\value{
A list with the following components
\item{train}{list of the training splits used}
\item{test}{list of the testing splits used}
\item{mc_fits}{List of length Kfold. Each element is a mc_reg() object that was fit on a training split.}
\item{fe}{A data frame of forecast errors. Includes CV prediction (yhat), observed value (y), class and knot.}
\item{pooled_fe}{}
\item{class_knot_fold_summary}{One MSFE and MAFE for each fold, knot, class combination.}
\item{class_knot_summary}{One MSFE and MAFE for each knot and each class.}
\item{knot_summary}{One MSFE and MAFE for each knot.}
\item{pooled_class_fold_summary}{One MSFE and MAFE for each fold and each class.}
\item{pooled_class_summary}{One MSFE and MAFE for each class.}
\item{pooled_summary}{One overall MSFE and MAFE for the pooled model.}
\item{fit_MSFE}{Data frame with the coefficients from the full fitted model that correspond to the optimal knot as defined by MSFE cross validation, this is a subset of \code{fit$coef_df} which is supplied as an argument to the CV function.}
\item{fit_MAFE}{Data frame with the coefficients from the full fitted model that correspond to the optimal knot as defined by MAFE cross validation, this is a subset of \code{fit$coef_df} which is supplied as an argument to the CV function.}
}
\description{
New function to compute optimal value of regularization parameter based on K-fold cross-validation
}
\examples{
p <- 7
k <- 2
n <- 500
beta <- c(1, 2)
set.seed(1)
X <- list(matrix(rnorm(p * n), ncol = p), matrix(rnorm(p * n), ncol = p))
Y <- list(rnorm(n), rnorm(n))
df = lists_to_data(Y, X)
res = mc_reg(df)
cv_res <- mc_cv(res)
}
