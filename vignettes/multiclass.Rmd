---
title: "Multiclass regression"
author: "Garth and Ines"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
    number_sections: true
---
  
```{r setup, include = FALSE}
knitr::opts_chunk$set(
collapse = TRUE,
  comment = "#>"
  )
library(dplyr)
library(multiclassreg)
```
  
This is for Garth to record how things are working in the simplest cases.

## No missing

The usual approach would be to have a data frame with predictors, class assignment and response as columns.
  
```{r}
p = 7
k = 2
n = 50
beta = c(1,2)
set.seed(1)
X = list(matrix(rnorm(p*n), ncol = p), matrix(rnorm(p*n), ncol = p))
Y = list(rnorm(n), rnorm(n))
df = lists_to_data(Y, X)
str(df)
```

We can go back the other way if we need to using `data_to_lists()`.  For example

```{r}
str(data_to_lists(df, class_var = "class", y_var = "y"))
```

Now we can use these with our functions.  The **new** function `mc_reg()` takes in a data frame and calls the underlying function `multiclass_reg()`.

```{r}
colnames(df)
set.seed(1)
res1 = mc_reg(df, class = "class", y = "y", scale = FALSE, center_y = FALSE)
```

Now the `res1` object has a few things:

```{r}
names(res1)
```

In particular, the `coef_df` data frame has the degrees of freedom included as a column called `df`.

```{r}
head(res1$coef_df)
res1$coef_df %>% dplyr::select(knot,df) %>% dplyr::distinct()
```

What happens when there are missing classes?

```{r}
df$V1[df$class == "A"] = NA
df$V7[df$class == "B"] = NA
res2 = mc_reg(df)

plot(res2, coef_type = "scaled")
# cv_res2 = multiclass_cv(res2)
```


Can do cross validation:


```{r}
# cv_res1 = multiclass_cv(res1)
set.seed(1)
res2 = multiclass_reg(Y, X)
# cv_res2 = multiclass_cv(res2)
# all.equal(cv_res1,cv_res2)
```

Great! these two approaches are giving identical results.  So we have a data frame method and a list based method.

Now, the scaling (both of the data and coefficients) will be done in the data frame wrapper function, `mc_reg()`.  There is a parameter `scale` with the default being `scale = TRUE`.

Some agreed practices around scaling:

- for the **predictors**, scaling is done ignoring the class variable (any binary predictors are also scaled)
- the **dependent variable** is mean centered to the class mean (so we don't need an intercept for each class) but we don't scale the dependent variable

This is the code that I'm using to center the Y's, I think it's OK (took me an embarassingly long time to figure it out, a simple but general enough approach to demeaning in a class-wise manner with custom y_var and class_var names).

```{r}
class_var = "class"
y_var = "y"
df = lists_to_data(Y, X)
data = df
data[y_var] = data[y_var]-tapply(data[[y_var]],data[[class_var]], mean, na.rm=TRUE)[data[[class_var]]]
```

Note that (as expected) we get different results under when we scale the variables.  The scaling is done in the `mc_reg()` function, not in the workhorse `multiclass_reg()` function.

```{r}
set.seed(1)
res1 = mc_reg(df, class = "class", y = "y", scale = TRUE, center_y = TRUE)
# cv_res1 = multiclass_cv(res1)
set.seed(1)
res2 = multiclass_reg(Y, X)
# cv_res2 = multiclass_cv(res2)
# all.equal(cv_res1,cv_res2)
```

So the procedure in the `mc_reg()` function now is:

1) Take a copy of the original data frame
2) Generate class means for the y's
3) Subtract off the class means for the y's
4) Calculate mean and sd for the predictors, store these
5) Scale the predictors
6) Generate the lists needed for the `multiclass_reg()` function
7) Run the `multiclass_reg()` function on the appropriately scaled data
8) Calculate the predicted values and add back in the class means, add thest to the output object as `fitted_values`.  Note that there is a set of fitted values for each penalty parameter, i.e. we have a matrix of fitted values.
9) Calculate the residuals and add these to the output object as `residuals`. Note that there is a set of residuals for each penalty parameter, i.e. we have a matrix of fitted values.
10) Create a matrix of rescaled coefficients using the standard deviations of the data calculated in step 4)

So let's test it out on a sligtly more complex example and see if it's doing what we think it should do.

```{r}
p = 7
k = 2
n = 50
set.seed(1)
# Xk <- mvtnorm::rmvnorm(n*2, mean=1:p, sigma=diag(1:p)) %>% round(2)
# yk <- Xk %*% c(0,0,4,0,0,8,0) + rnorm(n*2) + rep(c(0,10), each = n) %>% round(2)

X1 <- mvtnorm::rmvnorm(n, mean=1:p, sigma=diag(1:p)) %>% round(2)
y1 <- X1 %*% c(0,0,6,0,0,8,0) + rnorm(n) + rep(0, each = n) %>% round(2)
X2 <- mvtnorm::rmvnorm(n, mean=1:p, sigma=diag(1:p)) %>% round(2)
y2 <- X2 %*% c(0,0,2,0,0,4,9) + rnorm(n) + rep(10, each = n) %>% round(2)
Xk = rbind(X1,X2)
yk = rbind(y1,y2)

df = data.frame(y = yk, Xk, class = rep(c("A", "B"), each = n))
boxplot(df$y ~ df$class)
plot(df$y ~ df$X3)
lm(y ~ ., data = df) %>% summary()
```

OK so that looks good, has a little bit of structure at least.  Let's try a multiclass approach to see if we can recover the unscaled predictions and coefficients.

```{r}
res = mc_reg(df, class_var = "class", y_var = "y")
plot(res) +
  ggplot2::geom_vline(xintercept = res$bic$knot[which.min(res$bic$bic2)]
)

plot(res) +
  ggplot2::geom_vline(xintercept = res$bic$knot[which.min(res$bic$bic1)]
)
res$bic
# the coefficient data frame (scaled and rescaled)
res$coef_df
```

Well that's looking pretty great!

```{r}
res$predictions %>% dplyr::group_by(knot, df) %>% 
  dplyr::mutate(
    ydiff = abs(y-yhat)
      ) %>% 
  ggplot2::ggplot() + 
  ggplot2::aes(x = knot, y = ydiff) + 
  ggplot2::geom_point()

res$predictions %>% dplyr::group_by(knot, df) %>% 
  dplyr::summarise(
      sigma2 = mean((y-yhat)^2),
      df = mean(df),
      bic = dplyr::n() * log(sigma2) + df * log(dplyr::n())
      ) %>% 
  ggplot2::ggplot() + 
  ggplot2::aes(x = knot, y = sigma2) + 
  ggplot2::geom_point()
```


What about our fitted values?

```{r}
plot(res$fitted_values[,1] ~ df$y)
```

Excellent, so it looks like are now outputting fitted values and coefficients on the same scale as the original data, even though internally the data is scaled before being passed through to the `multiclass_reg()` function.

## Generic plot function

Should I reverse ordering of the the labelled knots?

```{r}
plot(res) + ggplot2::labs(title = "Knot with rescaled coefficients")
plot(res, coef_type = "scaled") + 
  ggplot2::labs(title = "Knot with scaled coefficients")
plot(res, plot_type = "lambda") + 
  ggplot2::labs(title = "Lambda with rescaled coefficients")
```

OK how does it work with the cross validation method?

```{r}
# res_cv_traditional = multiclass_cv(res)
res_cv_new = mc_cv(res)
```

```{r}
res_cv_new$class_knot_summary %>%
  dplyr::mutate(knot = as.numeric(knot)) %>% 
  ggplot2::ggplot(ggplot2::aes(x = knot, group = class)) +
  ggplot2::geom_point(ggplot2::aes(y = MSFE), colour = "red") +
  ggplot2::geom_line(ggplot2::aes(y = MSFE), colour = "red") +
  ggplot2::facet_wrap(~class)
```

The MAFE and M methods clearly aren't working.  Need to investigate further.


```{r}
fit = res
Kfold = 5
nweight = NULL
weighting = TRUE
wtype = "size"
type = "MSFE"
l1length = 100
normalize = TRUE

# can run existing CV on this object
# cv_old = multiclass_cv(fit, Kfold = Kfold,
#                        nweight = nweight, weighting = weighting,
#                        wtype = wtype, type = type,
#                        l1length = l1length, normalize = normalize)

# new CV approach

# assign observations to fold groups
group = fit$raw_data[[fit$class_var]]
fold_id = caret::createFolds(y = factor(group), 
                             k = Kfold, 
                             list = FALSE)

# initialise result storage objects
cv_fits = train = test = list()

# run the mc_reg() function over the Kfolds and
# capture the results
for(fold in 1:Kfold){
  train[[fold]] = fit$raw_data[fold_id != fold,]
  test[[fold]] = fit$raw_data[fold_id == fold,]
  # note the problem here, there's different scaling for each fold
  # kind of want to hold the scaling constant across the folds
  cv_fits[[fold]] = mc_reg(train[[fold]], 
                           class_var = fit$class_var,
                           y_var = fit$y_var,
                           scale = fit$scale,
                           center_y = fit$center_y)
  
}
```


```{r}
plot(cv_fits[[1]]$fitted_values[,1] ~ train[[1]]$y)
abline(a = 0,b = 1)
```


```{r}
# OK now we need to evaluate performance for each run
# we need to do this on the standardised scale
# as well as the original scale

# the coef_df table has the coefficients on the standardised
# scale as well as the rescaled coefficients

# head(fit$coef_df)

# generate standardised and rescaled predictions for the testing data set
# pull out the X matrix for each class in the test set:

# data_to_lists(fit$coef_df, class_var = )
# data_to_lists(test[[1]], class_var = fit$class_var, y_var = fit$y_var)$X


# an attempt using the standardised approach
forecast_errors = list()
for(i in seq_len(Kfold)){
  test_data = test[[i]]
    # don't scale the class var nor the dependent variable
    scale_cols = colnames(test_data)[!colnames(test_data)%in% c(class_var, y_var)]
    col_means = test_data %>% dplyr::ungroup() %>% dplyr::summarise_at(.vars = dplyr::vars(scale_cols), mean, na.rm = TRUE)
    col_sds = test_data %>% dplyr::ungroup() %>% dplyr::summarise_at(.vars = dplyr::vars(scale_cols), sd, na.rm = TRUE)
    test_data = test_data %>% dplyr::ungroup() %>% dplyr::mutate_at(.vars = dplyr::vars(scale_cols), function(x) (x - mean(x, na.rm = TRUE))/sd(x, na.rm = TRUE))
  
  
  # sequential observation identifier (required for matching later)
  test_data$obs_no = 1:nrow(test_data)
  # make the class variable namified (so don't run into issues later)
  test_data$class = make.names(test_data$class)
  # extract a data frame with the y data
  test_y_data = test_data[,c("obs_no", fit$y_var, fit$class_var)]
  # define the x testing data frame (removing the y variable)
  test_x_data = test_data
  test_x_data[[fit$y_var]] = NULL
  # convert the x data frame into long form
  test_x_data_df = tidyr::gather(test_x_data, key = x_var,
                                 value = x_value, -class, -obs_no)
  # calculate the forecast errors by joining the x data in
  # with the coefficient date frame, this repeats the
  # estiamted coefficients down the data frame for the 
  # number of observations in each variable and class
  forecast_errors[[i]] = dplyr::left_join(cv_fits[[i]]$coef_df, 
                                          test_x_data_df, 
                                          by = c("class","x_var")) %>% 
    dplyr::group_by(obs_no, class, knot) %>% 
    dplyr::summarise(rescaled_forecast = sum(coef * x_value)) %>% 
    dplyr::ungroup() %>% 
    dplyr::left_join(test_y_data, by = c("obs_no", "class")) %>% 
    dplyr::mutate(rescaled_fe = !!rlang::sym(fit$y_var) - rescaled_forecast)
}

# forecast_errors %>% ggplot(aes(x = ))
```


```{r}
# forecast_errors = list()
# for(i in seq_len(Kfold)){
#   
#   lst = data_to_lists(test[[i]], class_var, y_var)
#   
#   unadjusted_yhat = lst[[2]] %*% cv_fits[[i]]$coef
#   
#   test_data = test[[i]]
#   # sequential observation identifier (required for matching later)
#   test_data$obs_no = 1:nrow(test_data)
#   # make the class variable namified (so don't run into issues later)
#   test_data$class = make.names(test_data$class)
#   # extract a data frame with the y data
#   test_y_data = test_data[,c("obs_no", fit$y_var, fit$class_var)]
#   # define the x testing data frame (removing the y variable)
#   test_x_data = test_data
#   test_x_data[[fit$y_var]] = NULL
#   # convert the x data frame into long form
#   test_x_data_df = tidyr::gather(test_x_data, key = x_var,
#                                  value = x_value, -class, -obs_no)
#   # calculate the forecast errors by joining the x data in
#   # with the coefficient date frame, this repeats the
#   # estiamted coefficients down the data frame for the 
#   # number of observations in each variable and class
#   forecast_errors[[i]] = dplyr::left_join(cv_fits[[i]]$coef_df, 
#                                           test_x_data_df, 
#                                           by = c("class","x_var")) %>% 
#     dplyr::group_by(obs_no, class, knot) %>% 
#     dplyr::summarise(rescaled_forecast = sum(rescaled_coef * x_value)) %>% 
#     dplyr::ungroup() %>% 
#     dplyr::left_join(test_y_data, by = c("obs_no", "class")) %>% 
#     dplyr::mutate(rescaled_fe = !!rlang::sym(fit$y_var) - rescaled_forecast)
# }
# 
# # OK now we have the forecast_error list for each fold.  Let's combine it 
# # into a single data frame
# 
# fe = dplyr::bind_rows(forecast_errors, .id = "fold") %>% 
#   dplyr::mutate(knot = as.numeric(knot))


```


This still works because I haven't removed any objects from the output, only added new objects. However, it doesn't take in to account any rescaling.  So we need to do that.

## Still to do

- think about residual plots... particularly class specific residual plots, perhaps we will be able to identify that some classes are being fit better than others through their residuals?

- Throw in the application

- Small simulation study




